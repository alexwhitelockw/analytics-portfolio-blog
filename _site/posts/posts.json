[
  {
    "path": "posts/2021-02-18-wine-reviews/",
    "title": "Wine Reviews",
    "description": "In this post I undertake a text-mining analysis of wine reviews obtained from Kaggle. I show that using both tf-idf and topic-modelling provides interesting insights into the words used to describe wines of different countries.",
    "author": [
      {
        "name": "Alex Wainwright",
        "url": "https://github.com/alexwhitelockw"
      }
    ],
    "date": "2021-02-23",
    "categories": [
      "wine",
      "text mining"
    ],
    "contents": "\n\n\n\n\n\n\nOverview\nThe following analysis uses the wine review data from Kaggle. It (the data) contains 14 columns, but we are only going to be concerned with three: country, the country from which the wine originated; description, the review of the wine; and variety, the grape type. With the removal of duplicates and rows containing missing values, the data contains 89123 rows.\nFor this post, the following steps will be taken in the analysis:\nAn exploration of keywords across a select number of countries;\nAn exploration of keywords across a select number of varieties;\nand, a topic modelling of reviews for wines originating from France, Italy, and Spain.\nKeyword Exploration\nKeywords will be identified using tf-idf, which involves weighting the frequency of a term within a document by the frequency of a word across documents. In other words, if a word is not found across many documents it can be thought of as important to the document in question.\nBelow, we explore tf-idf in relation to the variables of country and variety of wines. For each variable, we are only taking a subset of the data, especially when we have 46 and 619 unique countries and varieties, respectively.\nCountry Words\nFigure 1 presents the keywords associated with the wine of 11 different countries. For most cases, the top word is the main variety of wine for the country (e.g., Malbec is the leading grape in Argentina). Beyond the grape names, we can see that the remaining words are descriptors of the wine itself. Taking France as an example, we can see that the wine is described by the words fruits, wood, and character.\n\n\n\nFigure 1: Top keywords associated with the wines of 11 different countries based on tf-idf values. In majority of cases, the first word in each sub-plot is the wine variety for that country. Beyond this, it can be seen that different words are used to describe the wines of the country. For example, Picpoul is associated with the words apply, brisk, and kumquat.\n\n\n\nVariety Words\nFigure 2 presents the keywords associated with 13 grape varieties. Here again, we can see the top words are generally the varieties themselves, but the words that follow are, on the whole, adjectives used to describe the wine. Pinot Noir, for instance, is described using the words cherry, cola, and raspberries.\n\n\n\nFigure 2: Top keywords associated with the wines of 13 different varieties based on tf-idf values. In majority of cases, the first word in each sub-plot is the wine variety for that country. The words following are descriptors of the wine itself. For example, Rosé is described with the words cherry, strawberry, and raspberry.\n\n\n\nTopic Modelling\nPrior to analysing the data with topic modelling, we will reduce the data to a subset of countries, specifically: France, Italy, and Spain. These three countries were selected due to being the largest producers of wine in the world (in 2014). Table 1 presents the number of reviews associated with each of the countries selected for the topic model analysis. Whereas, Table 2 presents the count of varieties within the aforementioned three countries, specifically with a review count value exceeding 1000.\nEU County Counts\n\nTable 1: Number of reviews for each of the countries selected for the topic model analysis. It can be seen that Italian wines have a higher number of reviews, whilst Spanish wines have the fewest.\nCountry\nN\nSpain\n5370\nFrance\n10185\nItaly\n12155\n\nVariety Counts\n\nTable 2: Number of reviews exceeding 1000 for each of the wine varieties within the three countries (France, Italy, and Spain) chosen for the topic model analysis. It can be seen that Red Blend wines have a higher number of reviews followed by Chardonnay.\nVariety\nN\nTempranillo\n1348\nSangiovese\n1477\nRed Blend\n2909\nChardonnay\n1846\nPinot Noir\n1098\nBordeaux-style Red Blend\n1678\n\nTopic Extraction\nThe structural topic modelling package is used to analyse the reviews across the three countries (France, Italy, and Spain). In regards to model specification, we specify that the prevalence of a topic varies across country. Therefore, K-1 dummy variables are created with the baseline category being Italy (most frequent category). In addition to this, stemming was applied to the review data and the word ‘wine’ was dropped.\n\n\n\nAs there was information on the number of topics to extract, we follow a data-driven approach to identifying a suitable number of topics. Below we use the furrr package to run 10 topic models and extract the Exclusivity and Semantic Coherence values from each run. Exclusivity is a measure of how exclusive a word is to a topic; whereas, Semantic Coherence provides a measure of topic coherence (i.e., do the words forming a topic make sense semantically?). As shown in Figure 3 we can see these values (Exclusivity and Semantic Coherence) plotted against one another for models with 8, 10, 14, and 18 topics. If we look at the model with 18 topics, it can be seen that exclusivity is maximised yet semantic coherence becomes a lot lower for certain topics. An 8 topic solution, on the other hand, does show the exclusivity values to be quite spread out, whilst semantic coherence does not appear as problematic. A 10 topic model, does appear as a good balance between exclusivity and semantic coherence, and for this reason it was selected as the candidate model.\n\n\nk <- seq(2, 20, 2)\n\ntm_model_check <-\n  furrr::future_map(k, function(topic) {\n    tm_mod <-\n      stm(\n        documents = wine_reviews_prep$documents,\n        vocab = wine_reviews_prep$vocab,\n        K = topic, \n        prevalence = ~ country_France + country_Spain,\n        data = wine_reviews_prep$meta,\n        verbose = F\n      )\n    exclus <- exclusivity(tm_mod)\n    sem_coh <- semanticCoherence(tm_mod, wine_reviews_prep$documents)\n    mod_opt <- list(topic=topic, exclusivity=exclus, semantic_coherence=sem_coh)\n    return(mod_opt)\n  })\n\ntm_model_check <-\n  rbindlist(tm_model_check)\n\nggplot(tm_model_check[topic %in% c(8,10,14,18)], aes(x = exclusivity, y = semantic_coherence,\n                           colour = as.factor(topic),\n                           shape = as.factor(topic))) +\n  geom_point(\n    size = 2.5\n  ) +\n  labs(\n    x = \"Exclusivity\",\n    y = \"Semantic Coherence\",\n    colour = \"Topic\",\n    shape = \"Topic\"\n  ) +\n  scale_colour_manual(values =  wes_palette(\"Darjeeling1\")) +\n  theme(\n    legend.position = \"bottom\",\n    legend.key = element_rect(\n      colour = \"black\",\n      fill = \"white\"\n    ),\n    panel.background = element_rect(\n      colour = \"black\",\n      fill = \"white\"\n    )\n  )\n\n\n\n\nFigure 3: Ten LDA models were ran in increments of 2, starting from a 2 topic model up to a 20 topic model. For each model, the semantic coherence and exclusivity of the topics were extracted. A good balance between exclusitivty and semantic coherence seems to be found with a 10 topic model.\n\n\n\nModel Run\nFigure 4 presents the expected topic proportions (based on the document-topic matrix) along with the top five words associated with each topic (based on the word-topic matrix). To flesh out these topics, we will present two relevant quotes for each of the top 4 topics (1, 4, 7, and 9).\n\n\n\nFigure 4: Expected topic proportions across wine reviews along with the top 5 words per topic. Topics 1 and 4 appear to be found across a far greater number of wine reviews and appear to refer to the ageing and acidity of wines, respectively. Topic 3, on the other hand, appears to be far less frequent across wine reviews.\n\n\n\n\n\n\nTopic 1 – Acidity of Wine\nAs shown in Figure 4, the main words associated with Topic 1 are: acid, flavor, fresh, fruit, and fruiti. The quotes below both use the words fresh and acid to describe the wines, suggesting that Topic 1 is capturing wine acidity. According to this article, the acidity of a wine refers to the “fresh, tart, and sour attributes”.\n\n\n\nTopic 4 – Aging of Wine\nTopic 4 has the following top words associated with it: fruit, age, tannin, year, and rich (Figure 4). Both quotes that follow describe the wines in relation to the wine’s age, its intensity, and the level of tannins. From this, we can think of Topic 4 as capturing reviews towards those wines that have been aged.\n\n\n\nTopic 7 – Aroma of Wine (Red)\nTopic 7 is associated with the following words: spice, cheri, fruit, aroma, and soft (Figure 4). The two quotes associated with this topic show reviews that are centered upon the aroma of the wine, describing such things as the spice and tobacco. This topic can be discerned from Topic 9 as it appears that Topic 7 is specifically describing the aroma of red wines.\n\n\n\nTopic 9 – Aroma of Wine (White)\nTopic 9 is associated with the following words: aroma, white, fruit, fresh, and almond (Figure 4). From both quotes that follow, it can seen that the reviews are focused on the aromas of the wine, describing them in terms of citrus, cut grass, and white flower. As mentioned above, this topic is focused on the aromas of white wines, whilst Topic 7 was capturing reviews describing the aroma of red wines.\n\n\n\nCovariate Effects\nAs stated above, the topic model included covariates for topic prevalence; these covariates were dummy coded with Italy as the baseline. The plots that follow show the difference between the baseline (Italy) and each condition (France and Spain). To remain consistent with the aforementioned topic modelling results, the covariate effects with only be discussed in relation to Topics 1, 4, 7, and 9.\n\n\n\nFrance compared to Italy\nFigure 5 presents the difference in topic prevalence between France and Italy. For Topic 1 and 4, the prevalence in reviews was greater for wines from France. Topic 7 and 9 were less likely in French wine reviews compared to Italian wine reviews. This may suggest that French wines are fresh and tart, probably when it comes to white wines. Whereas, for red wines they are more likely to be aged and bold in flavour. Italian wines reviews, on the other hand, have a higher propensity of topics associated with the aromas of the wine (i.e., Topics 7 and 9).\n\n\n\nFigure 5: Topic prevalence differences between France and Italy (Italy is used as the baseline country).\n\n\n\nSpain compared to Italy\nFigure 6 shows that there are no meaningful differences for the topic prevalence of Topic 1 or 4 between Spain and Italy. As with French wine reviews, Spanish wine reviews are less likely to contain topics about the aromas of the wine.\n\n\n\nFigure 6: Topic prevalence differences between Spain and Italy (Italy is used as the baseline country).\n\n\n\nSummary\nUtilising different text-mining approaches, we have been able to explore a collection of wine reviews. Keyword extraction provided a succinct way of summarising wine reviews by both country and variety. Whereas, topic modelling provided greater depth in the exploration of wine reviews, particularly with the inclusion of covariates.\n\n\n\n",
    "preview": "posts/2021-02-18-wine-reviews/wine-reviews_files/figure-html5/countryTfidf-1.png",
    "last_modified": "2021-02-24T13:17:48+11:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-18-melbourne-covid-megathread-repost/",
    "title": "Melbourne Covid Megathread",
    "description": "This post details the analysis of posts made on the Melbourne Reddit covid megathread over the period of 7 months.",
    "author": [
      {
        "name": "Alex Wainwright",
        "url": "https://github.com/alexwhitelockw"
      }
    ],
    "date": "2021-02-18",
    "categories": [
      "reddit",
      "text mining"
    ],
    "contents": "\nOverview\nTo keep myself sane during lockdown, I decided to analyse public opinion towards the Victorian lockdowns, specifically those opinions vocalised on Reddit. Below you’ll find various pieces of analysis of megathread posts covering the period from ‘2020-03-03’ to ‘2020-09-13’.\nPosting Behaviour\n\n\n\nFigure 1 shows the daily count of posts during the time frame (2020-03-03 to 2020-09-13), along with the 14 day average (in red). Key events in the Covid-19 timeline for Victoria have been marked with the view of providing some context to the posting behaviour, specifically those events during the second wave. The main takeaway from the Figure 1 is how the number of posts has followed the waves, with relatively low post numbers between March and April, and a uptake in posting that began to steadily rise towards the end of June.\n\n\n\nFigure 1: Daily number of posts in the Covid-19 megathread over the period of 2020-03-03 to 2020-09-13. The white line shows the raw daily count of posts, whilst the red line is the 14 day average. It can be seen that posting on the megathread was particularly low during the first wave, yet surged during Victoria’s second wave. Key dates during the second wave have been highlighted to provide context for posting behaviour.\n\n\n\nPosting During the First Wave\nCases of Coronavirus began to rise in Victoria during March, resulting in Daniel Andrews (Premier of Victoria) declaring a State of Emergency on the 16th of that month. This also corresponded to the time when panic buying was all the rage, and daily excursions to locate toilet paper were not uncommon. In the realm of the Melbourne sub-Reddit, posts associated with Covid-19 were also on the rise (Median # of posts per day in March = 508; median absolute deviation = 333.58). The median absolute deviation shows that, on average, the number of day-to-day postings during March were 333.58 posts away from the median.\nThere is quite a lot of spread in the number of posts made during the month of March, with some days being particularly low (e.g., 75 posts on 2020-03-05), whilst some were relatively high (e.g., 1136 posts on 2020-03-17). Interestingly, these 1136 posts fell on the day after the state of emergency was declared. Table 1 presents a random sample of 5 posts from 2020-03-17. The topic of ‘panic buying’ is quite clear from this sample of messages, with some posters referencing supermarkets running out of toilet paper, whilst others appear to have prepped for this situation.\n\n\n\n\nTable 1: A random sample of 5 posts taken from 2020-03-17, corresponding to the date following the State of Emergency being declared in Victoria. General themes in these posts include the lack of toilet paper in supermarkets, prepping for the supposed apocalypse, and following social distancing guidelines.\nCreated Date\nPost Text\n2020-03-17\nWe’re being made to go into work, despite a confirmed case in our building :-( Take whatever steps you can to keep yourself safe. I hope they change the mandatory attendance requirements for your class soon\n2020-03-17\nSpend some time in r/conspiracy\n2020-03-17\nYeah, I ain’t gonna be hugging randoms anytime soon, but I’m certainly getting out on the bike with these quieter roads!\n2020-03-17\nMaybe just be prepared in the future? Why is panic buying or having nothing the only 2 options? At the start of the year i made sure to buy an extra 24 pack of toilet paper and a months food for my partner and myself, as well as cleaning supplies, soap, board games etc As a result we are not worried about food supplies or toilet paper as we prepared in advance and we are not taking away supplies from poor or elderly people. Dont blame your lack of foresight on others, you control your life\n2020-03-17\nJust did a walk through a lot of the CBD (I live here), no TP anywhere.\n\nPosting During the Second Wave\nDespite lockdown relaxations around the beginning of June, these were short-lived. By the 20th June various restrictions came into force, with postcode lockdowns being enforced on the 30th June. During the month of June we can see a stark contrast in posting behaviour. If we take the period from the 2020-06-01 to 2020-06-19 (inclusive), the median number of posts were 44 (median absolute deviation = 25.2042). Compare this to period between 2020-06-20 to 2020-06-30, wherein the median number of posts rose to 294 (median absolute deviation = 139.3644), representing a 7-fold increase in the average day-to-day posting.\nReturning to Figure 1, there are three discernible peaks in posting behaviour over the period of July to September. These peaks align with various lockdown announcements. On 2020-07-07, when Stage 3 Stay at Home restrictions were announced, there were 4304 posts made. 2020-08-02 was when the State of Disaster was declared and the move to Stage 4 restrictions; the number of posts made on this day was 7295. Finally, on 2020-09-06 the Roadmap was unveiled, resulting in another uptick in postings (8277).\nTable 2 contains a random sample of 15 sentences from the aforementioned dates (i.e., ‘2020-07-07’, ‘2020-08-02’, and ‘2020-09-06’). The sentences were first obtained by concatenating the posts for each date and applying the Gensim summarizer function to summarise the messages. For the ‘2020-07-07’, messages seem to refer to questions around leaving metro Melbourne for regional areas and the concern around spending 6 weeks in lockdown. Messages on ‘2020-08-02’ seem to be centred on seeking clarification for the various Stage 4 restrictions and vocalising their feelings of apathy towards a pro-longed lockdown. One message in the sample is associated with ‘2020-09-06’ and succinctly summarises how we should not get into the habit of focusing on daily case announcements.\n\n\n\n\nTable 2: Sample of 15 sentences across the dates of ‘2020-07-07’, ‘2020-08-02’, and ‘2020-09-06’. These sentences were obtained by applying the gensim summarizer function to a concatenated list of posts for each of the aforementioned dates. In this way, there is a likelihood that two or more sentences could originate from a single post.\nCreated Date\nPost\n2020-07-07\nI’m renting in Melbourne but my family lives in regional Vic. Any idea if I could move home in (for example) a few weeks if everything goes to shit?\n2020-07-07\nThat’s fair enough but it still happened here while we had active community cases, and the stuff I saw from friends on social media wasn’t in line with social distancing practices and is likely still contributing, we still have a whole bunch of untraced cases and people heeding my advice and being more conscious of the impact of behaving that way is worth people considering regardless of the other factors that lead to this.\n2020-08-02\nwhy do we listen to all these elected leaders, that are informed by teams of professionals that are considered experts in their fields, when we have people like you around?\n2020-07-07\nIt’s worth keeping in mind that this is a very infectious and very nasty virus, and for a city of nearly 5m people, we’re overall doing a pretty good job of keeping it under control.\n2020-07-07\nCovids are thinking exactly the same No we didn’t, clearly the virus was still out there last time when people were supposed to be self-isolating, and it ain’t leaving.\n2020-08-02\nIf your business dosnt facilitate essential supplies or pharmacist / providing care, I imagine your business will be either work from home, or flat out closed.\n2020-08-02\nFor those interested, here’s today (Sunday August 2)’s press conference: https://www.youtube.com/watch?v=rkYfnfYwO8o pretty much sums up this week…\n2020-07-07\nYour government is about a week behind where they need to be.\n2020-08-02\nit worked in every other country No, see Dan is secretly hoping people will start killing themselves off and going into deep depression because his ultimate goal is to watch the state crumble and burn…\n2020-08-02\nHopefully they don’t ban movers though, I am married to a ‘collector’ and have a lot of things They specifically say you’re allowed 5ks from the location you sleep, if you’re moving then that’s fine.\n2020-08-02\nI completely agree and someone who has lived almost their entire life and whats more as part of a privileged generation should not be the determining factor in destroying our nations economy and the mental health of people with their whole lives ahead of them.\n2020-07-07\nI also understand six weeks might feel like an eternity.\n2020-09-06\nWe absolutely can’t get into a world of \"“we need less than X cases per day before we open”\"…\n2020-08-02\nCan only think it’s to prevent parties/gatherings and people avoiding police by travelling at night.\n2020-08-02\nPushing the blame to people after hotel quarantine, contact tracing and age care fail AND when most contaminations occurred in work places.\n\nSentiment Analysis\nFigure 2 presents the day-to-day distribution of the Vader compound scores, facetted by month. The use of Vader to measure sentiment is applicable in this context as it is suited to social media data. The compound score corresponds to a normalisation of the summed valence scores across words within the message. As can be seen in Figure 2, compound scores appeared to be quite variable in the months of April, May, and June. Given that the number of posts during these months were relatively low, these distributions are not unexpected. During those months wherein posting behaviour was higher (March, July, August, and September), we can see that the day-to-day compound score had a peak at 0. It may be the case that posts were generally neutral, outweighing those that were overly positive or negative in sentiment. We also have to consider the confounding factor that messages will have been moderated to an extent; therefore, we may not be seeing a complete representation of postings.\n\n\n\nFigure 2: Day-to-day distribution of Vader Compound Scores for each post across each month. Plots show that there was a high variability in compound scores during April, May, and June, which is a likely a result of there being a smaller number of posts during these months. Months such as July and August show the distributions to peak at 0, a likely result of there being a far greater number of posts during this time.\n\n\n\nSummary\nAlthough not representative of the larger population, posting behaviour within the megathread has offered some interesting insights. For one, it can be seen that posting has seemingly followed the number of reported infections. As this data only reflects up to ‘2020-09-13’ this conclusion is, however, limited. In conjunction with the information of the message content, we can also see how topics within the posts have shifted over the course of these 7 months.\nTo end this post, I present Figure 3 that presents keywords (using the Gensim keywords function) from those messages with a Vader compound score exceeding .4 (i.e., they have a positive sentiment).\n\n<wordcloud.wordcloud.WordCloud object at 0x7f9e12447490>\n(-0.5, 755.5, 979.5, -0.5)\n\n\nFigure 3: Wordcloud of those keywords in messages with Vader compound scores exceeding the value of .4\n\n\n\n\n\n\n",
    "preview": "posts/2021-02-18-melbourne-covid-megathread-repost/melbourne-covid-megathread-repost_files/figure-html5/postplot-1.png",
    "last_modified": "2021-02-24T12:17:35+11:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-06-frasier-analysis/",
    "title": "Frasier Analysis",
    "description": "In this post I undertake a descriptive and text mining analysis of the lines spoken on Frasier.",
    "author": [
      {
        "name": "Alex Wainwright",
        "url": "https://github.com/alexwhitelockw"
      }
    ],
    "date": "2021-02-06",
    "categories": [
      "frasier",
      "text mining"
    ],
    "contents": "\nOverview\nAfter re-watching Frasier a few times over the course of the Victoria lockdowns, I decided to undertake a project to extract and analyse text contained in the Frasier scripts. After a weekend spent getting to grips with the BeautifulSoup and Request libraries, I have managed to extract and clean the data (not 100% guaranteed). The original data source can be found here and can be downloaded here.\n\n\n\nCharacter Lines\nBy Season\nLet’s first start by exploring some descriptives assoicated with the number of lines each character has across the 11 seasons. Focus of this analysis is solely on the five main characters: Daphne, Frasier, Martin, Niles, and Roz. Table 1 and Figure 1 show the average number of lines per character across seasons. We can see that Frasier obviously dominates in the number of lines spoken and, for the most part, varying between 80 to 90 lines per season. However, seasons 9 and 10 show a dip to 70 and 67 lines, respectively. It may have been the case that episodes across these 2 seasons emphasised other characters (e.g., Roz’s new job and Nile’s heart surgery take place in season 10). Nile’s lines peaked in season 6, which is understandable as his story centers on his divorce from Maris.\n\nTable 1: The average (mean) number of lines for each of the five main characters on Frasier across 11 seasons. As expected, Frasier consistently has the highest number of lines of any of the characters, followed by Niles and Martin. Daphne and Roz appear to be comparable, but have far fewer lines over the seasons than Frasier, Martin, or Niles.\nCharacter\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nDaphne\n18.75\n16.25\n17.92\n22.21\n24.75\n18.21\n23.54\n27.89\n24.12\n24.12\n18.70\nFrasier\n91.50\n84.21\n82.21\n81.04\n85.33\n92.75\n83.92\n80.33\n70.08\n66.67\n90.54\nMartin\n34.04\n28.29\n29.04\n30.38\n27.17\n33.00\n32.25\n25.75\n31.08\n30.29\n28.67\nNiles\n33.42\n35.25\n35.92\n43.79\n42.21\n52.46\n39.75\n44.29\n39.62\n37.21\n40.25\nRoz\n13.04\n18.25\n15.62\n16.92\n21.62\n23.08\n21.42\n20.33\n19.12\n23.71\n16.73\n\nMartin is quite consistent across the 11 seasons in regards to the average number of lines. The same can generally be said of Daphne and Roz. Interestingly, Roz did see an uptick in lines beyond season 1.\n\n\n\nFigure 1: Average (mean) number of lines spoken by the five main characters in Frasier across 11 seasons.\n\n\n\nBy Episode\nFigure 2 presents the number of lines by each of the main characters at the level of each episode. From this perspective, we can see far more clearly as to why Frasier seemingly showed, on average, fewer lines during seasons 9 and 10. Additionally, you can see occasions when the number of lines spoken by Niles exceeds those of Frasier. For example, Kelsey Grammer directed Season 3 Episode 13 (Moon Dance), resulting in the character of Frasier making a very limited appearance. Instead, the episode largely focused on the dynamics between Niles and Daphne, hence the greater number of lines for these two characters. We can also see another occasion in Season 6 Episode 16 (Decoys) wherein Niles devises a plan to reunite Roz and her ex-boyfriend Donny.\n\n\n\nFigure 2: Number of lines spoken by the five main characters in Frasier across each episode for the 11 season run.\n\n\n\nKeywords\nBeyond an examination of the number of lines spoken by each of the main characters, we can also explore the keywords associated with each episode. To do this, we can use the Term Frequency - Inverse Document Frequency measure (tf-idf). This statistic is essentially the frequency of words multiplied by how common those words are across all documents (i.e., words that are found across many documents are downweighted, whilst rare words are assigned a higher weight). Given that there are 264 episodes of Frasier, exploring the keywords each episode would be tedious. Instead, a random sample of 5 episodes (Figure 3) is used and we will explore how well the keywords summarise each episode.\n\n\n\nFigure 3: Top words, based on tf-idf, across a random sample of 5 episodes.\n\n\n\nAnd the Dish Ran Away with the Spoon\nThis is a two part episode (Season 8 Episode 1 and 2) where Daphne and Niles confess their love to Donny and Mel. The associated keywords do well to summarise the episodes: the story centers on Daphne and Donny’s wedding and the aftermath of the aforementioned confession (e.g., Donny suing Daphne and Frasier).\nDial M for Martin\nThis is episode 3 of season 6, wherein Martin moves in with Niles to give Frasier space. Words such as Rebecca, model, and lingerie refer to Frasier’s date and her occupation. Stairs is mentioned a few times:\nin relation to Martin being physically able to walk up and down the stairs at Nile’s place;\nin reference to Niles pushing Martin down the stairs as a way to keep Daphne from leaving;\nand, in the end when Martin exclaims that he cannot walk up and down the stairs at Nile’s place.\nMy Coffee with Niles\nThis is episode 24 of season 1, which revolves around Frasier and Niles sitting in Cafe Nervosa mulling over his (Frasier’s) move to Seattle and whether he is happy. The words do well in summarising the plot as throughout the episode Frasier continually returns coffee for various reasons (not decaf, no non-fat milk). Bumbershoot is the term Daphne uses to describe an umbrella.\nMy Fair Frasier\nThis is episode 7 of season 5 where Frasier dates an attorney (Sam Pierce). Although only 4 keywords are presented, they do give the gist of the episode. In effect, Frasier is concerned that his new relationship, which started over the purchase of a purse, puts him in a position where he is not dominant.\nThe Ann who Came to Dinner\nFinally, we have episode 13 of season 11. As a result of Frasier’s fearing being sued (due to having no insurance), Ann moves in with him an Martin. We can also see the words trumpet, which is what Ann plays, and bunny, the nickname Ann uses for Frasier.\nConclusion\nAlthough brief, the analysis has shown how the number of lines per character changed over the 11 seasons. Moreover, the use of tf-idf has been helpful in identifying keywords that can do well in summarising episodes.\n\n\n\n",
    "preview": "posts/2021-02-06-frasier-analysis/frasier-analysis_files/figure-html5/linesPlot-1.png",
    "last_modified": "2021-02-24T11:58:28+11:00",
    "input_file": {}
  }
]
